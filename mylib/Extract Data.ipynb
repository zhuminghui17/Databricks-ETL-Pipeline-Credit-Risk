{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "38a9632b-1692-410c-86bc-a12c3bafd225",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Extract Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4149ec42-dfdc-4185-a2df-f9665e306714",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, count\n",
    "\n",
    "# Initialize a Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Credit Card Approval - Extract\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "file_path = \"dbfs:/FileStore/tables/credit_card_approvals.csv\"\n",
    "table_name = \"credit_card_approvals\"\n",
    "\n",
    "df = spark.read.csv(file_path, header=True, inferSchema=True)\n",
    "\n",
    "df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(table_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "53ea268e-0b04-4f99-a924-da46e53f2d01",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Validate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6951f524-cb3c-4073-9680-26e9aaf34b7c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'Missing Values': Row(Gender=0, Age=0, Debt=0, Married=0, BankCustomer=0, Industry=0, Ethnicity=0, YearsEmployed=0, PriorDefault=0, Employed=0, CreditScore=0, DriversLicense=0, Citizen=0, ZipCode=0, Income=0, Approved=0),\n",
       " 'Data Types': [('Gender', 'int'),\n",
       "  ('Age', 'double'),\n",
       "  ('Debt', 'double'),\n",
       "  ('Married', 'int'),\n",
       "  ('BankCustomer', 'int'),\n",
       "  ('Industry', 'string'),\n",
       "  ('Ethnicity', 'string'),\n",
       "  ('YearsEmployed', 'double'),\n",
       "  ('PriorDefault', 'int'),\n",
       "  ('Employed', 'int'),\n",
       "  ('CreditScore', 'int'),\n",
       "  ('DriversLicense', 'int'),\n",
       "  ('Citizen', 'string'),\n",
       "  ('ZipCode', 'int'),\n",
       "  ('Income', 'int'),\n",
       "  ('Approved', 'int')],\n",
       " 'Range Checks': {'Age': 0,\n",
       "  'Debt': 0,\n",
       "  'YearsEmployed': 0,\n",
       "  'CreditScore': 0,\n",
       "  'ZipCode': 0,\n",
       "  'Income': 0},\n",
       " 'Categorical Values': {'Gender': [Row(Gender=1), Row(Gender=0)],\n",
       "  'Married': [Row(Married=1), Row(Married=0)],\n",
       "  'BankCustomer': [Row(BankCustomer=1), Row(BankCustomer=0)],\n",
       "  'Industry': [Row(Industry='Education'),\n",
       "   Row(Industry='Energy'),\n",
       "   Row(Industry='Healthcare'),\n",
       "   Row(Industry='ConsumerStaples'),\n",
       "   Row(Industry='Real Estate'),\n",
       "   Row(Industry='CommunicationServices'),\n",
       "   Row(Industry='Materials'),\n",
       "   Row(Industry='ConsumerDiscretionary'),\n",
       "   Row(Industry='Research'),\n",
       "   Row(Industry='Utilities'),\n",
       "   Row(Industry='Industrials'),\n",
       "   Row(Industry='InformationTechnology'),\n",
       "   Row(Industry='Financials'),\n",
       "   Row(Industry='Transport')],\n",
       "  'Ethnicity': [Row(Ethnicity='Latino'),\n",
       "   Row(Ethnicity='Other'),\n",
       "   Row(Ethnicity='White'),\n",
       "   Row(Ethnicity='Black'),\n",
       "   Row(Ethnicity='Asian')],\n",
       "  'PriorDefault': [Row(PriorDefault=1), Row(PriorDefault=0)],\n",
       "  'Employed': [Row(Employed=1), Row(Employed=0)],\n",
       "  'DriversLicense': [Row(DriversLicense=1), Row(DriversLicense=0)],\n",
       "  'Citizen': [Row(Citizen='ByOtherMeans'),\n",
       "   Row(Citizen='ByBirth'),\n",
       "   Row(Citizen='Temporary')],\n",
       "  'Approved': [Row(Approved=1), Row(Approved=0)]},\n",
       " 'Duplicates': 0}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, when, count\n",
    "# 1. Checking for Missing Values\n",
    "missing_values = df.select([count(when(col(c).isNull(), c)).alias(c) for c in df.columns])\n",
    "\n",
    "# 2. Checking Data Types\n",
    "data_types = df.dtypes\n",
    "\n",
    "numerical_columns = ['Age', 'Debt', 'YearsEmployed', 'CreditScore', 'ZipCode', 'Income']\n",
    "categorical_columns = ['Gender', 'Married', 'BankCustomer', 'Industry', 'Ethnicity', 'PriorDefault', 'Employed', 'DriversLicense', 'Citizen', 'Approved']\n",
    "\n",
    "# 3. Range Checks\n",
    "range_checks = {c: df.filter((col(c) < 0) | col(c).isNull()).count() for c in numerical_columns}\n",
    "\n",
    "# 4. Categorical Data Consistency\n",
    "categorical_values = {c: df.select(c).distinct().collect() for c in categorical_columns}\n",
    "\n",
    "# 5. Checking for Duplicates\n",
    "duplicates = df.count() - df.dropDuplicates().count()\n",
    "\n",
    "# Summarizing the validation checks\n",
    "validation_summary = {\n",
    "    \"Missing Values\": missing_values.collect()[0],\n",
    "    \"Data Types\": data_types,\n",
    "    \"Range Checks\": range_checks,\n",
    "    \"Categorical Values\": categorical_values,\n",
    "    \"Duplicates\": duplicates\n",
    "}\n",
    "\n",
    "validation_summary\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Extract Data",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
